use opencv::{
    core::{Vec3b, CV_32F, CV_32FC1, CV_32FC3, CV_8UC1}, highgui, prelude::*, types::{VectorOfVec3f, VectorOfi32, VectorOfu8}, videoio, Error, Result
}; // Note, the namespace of OpenCV is changed (to better or worse). It is no longer one enormous.
use tokio::sync::mpsc; // Communicate data
use tokio::task; // threads
use std::f32::consts::{self, PI};
use image::{imageops::colorops, DynamicImage, ImageBuffer, Rgba}; 


fn process_frame(frame: &mut Mat, normalized_kernel: &Vec<Vec<f32>>) -> Result<(), Error> {

        let convolve_value_made = create_convolve_value(&frame, &normalized_kernel);
        if frame.cols() >= 1 && frame.rows() >= 1 {
            let columns = frame.cols();
            let rows = frame.rows();
            create_frame(frame, columns, rows, &convolve_value_made);
            // Step 4: Iterate over each pixel in the image
            println!("Grey Frame: {:#?}", frame);
            highgui::imshow("window", frame)?;
            let key = highgui::wait_key(1)?;
            if key == 113 { // quit with q
                return Err(Error::new(400, "Quit Program"));
            }
        }
    Ok(())
}

#[tokio::main]
async fn main() -> Result<()> { // Note, this is anyhow::Result
    let mut cam = videoio::VideoCapture::new(1, videoio::CAP_ANY)?;
    highgui::named_window("window", highgui::WINDOW_FULLSCREEN)?;

    let (sender, mut receiver) = mpsc::channel::<Mat>(100);
    let kernel_size = 5; // Or any other odd number
    let sigma = 1000.0;

    // Step 2: Generate Gaussian kernel
    let kernel = generate_gaussian_weight_kernel(kernel_size, sigma);

    // Step 3: Normalize the kernel
    let normalized_kernel = normalize_kernel(&kernel);



    // Spawn the camera task to asynchronously read frames and send them through the channel
    let camera_task = task::spawn(async move {
        loop {
            let mut frame = Mat::default();
            cam.read(&mut frame);

            if let Err(_) = sender.send(frame).await {
                break; // Channel closed, terminate the task
            }
        }
    });

    // Spawn the processing task to asynchronously receive frames and process them
    let processing_task = task::spawn(async move {
        while let Some(frame) = receiver.recv().await {
            let mut image_frame = frame;
            let output_image = colorops::grayscale(&mat_to_image(&mut image_frame).expect("Image to grayscale did not work"));    
            let (width, height) = output_image.dimensions();
            let mut gray_frame = Mat::new_rows_cols_with_default(height as i32, width as i32, opencv::core::CV_8UC1, opencv::core::Scalar::all(0.0)).unwrap();
            process_frame(&mut gray_frame, &normalized_kernel);

            
        }
    });





    // Open a GUI window
    // Open the web-camera (assuming you have one)
    /* let mut frame = Mat::default(); // This array will store the web-cam data
    // Read the camera
    // and display in the window

    let cached_covolution: Vec<Vec<f32>> = Vec::with_capacity(1500 * 1500);
    
    // Step 1: Define Gaussian kernel size and sigma
    let kernel_size = 5; // Or any other odd number
    let sigma = 1000.0;

    // Step 2: Generate Gaussian kernel
    let kernel = generate_gaussian_weight_kernel(kernel_size, sigma);

    // Step 3: Normalize the kernel
    let normalized_kernel = normalize_kernel(&kernel);
    loop {
        cam.read(&mut frame)?;



        let output_image = colorops::grayscale(&mat_to_image(&mut frame)?);    

        let (width, height) = output_image.dimensions();
        let mut gray_frame = Mat::new_rows_cols_with_default(height as i32, width as i32, opencv::core::CV_8UC1, opencv::core::Scalar::all(0.0)).unwrap();
        
        println!("{} {}", width, height);
        for y in 0..height {
            for x in 0..width {
                let pixel_value = output_image.get_pixel(x, y)[0];
                *gray_frame.at_2d_mut::<u8>(y as i32, x as i32).unwrap() = pixel_value;
            }
        }

        println!("Frame: {:#?}", gray_frame);
         // Iterate through each pixel
    /* for y in 0..gray_frame.rows() {
        for x in 0..gray_frame.cols() {
            // Access the pixel value at (x, y)
            let pixel_value = *gray_frame.at_2d::<u8>(y, x)?;

            // Print the pixel value (assuming it's a grayscale image)
            if pixel_value != 0 {
                                println!("Pixel at ({}, {}): {}", x, y, pixel_value);

                }
            }
    } */


        let convolve_value_made = create_convolve_value(&gray_frame, &normalized_kernel);
        if gray_frame.cols() >= 1 && gray_frame.rows() >= 1 {
            let columns = frame.cols();
            let rows = frame.rows();
            create_frame(&mut gray_frame, columns, rows, &convolve_value_made);
            // Step 4: Iterate over each pixel in the image
            println!("Grey Frame: {:#?}", gray_frame);
            highgui::imshow("window", &gray_frame)?;
            let key = highgui::wait_key(1)?;
            if key == 113 { // quit with q
                break;
            }
        }
    } */
    Ok(())
}

fn mat_to_image(mat: &mut Mat) -> Result<DynamicImage, Error> {
    if mat.channels() != 3 {
        return Err(Error::new(400, "Image must have three channels to be converted (BGR)"));
    }

    let width = mat.cols() as u32;
    let height = mat.rows() as u32;

    let mut rgb_image = ImageBuffer::<Rgba<u8>, Vec<u8>>::new(width, height);

    for y in 0..height {
        for x in 0..width {
            let bgr_pixel = mat.at_2d::<Vec3b>(y as i32, x as i32)?;

            let r = bgr_pixel[2];
            let g = bgr_pixel[1];
            let b = bgr_pixel[0];

            let rgba_pixel = image::Rgba([r, g, b, 255]);
            rgb_image.put_pixel(x, y, rgba_pixel);

        }
    }

    let dynamic_image = DynamicImage::ImageRgba8(rgb_image);
    Ok(dynamic_image)
}

async fn create_frame(output_image: &mut Mat, columns: i32, rows: i32, blurred_pixel_value: &Vec<f32>) {
    // Convert the output image to floating-point representation (CV_32FC1)
    let mut gray_frame = Mat::default();
    let mut index = 0;
    output_image.convert_to(&mut gray_frame, CV_32FC1, 1.0, 0.0).expect("Failed to convert to CV_32FC1");
    
    // Precompute kernel size and center

    for y in 0..rows {
        for x in 0..columns {
            // Assign the blurred pixel value to the output image
            *gray_frame.at_2d_mut::<f32>(y, x).expect("Failed to access pixel") = *blurred_pixel_value.get(index).expect("Pixel blurred cannot be assigned to new grayscale with 32 with 1 channel");
            index+=1;
        }
    }

    // Convert the output image back to CV_8UC1 (grayscale) for display
    gray_frame.convert_to(output_image, CV_8UC1, 1.0, 0.0).expect("Failed to convert to CV_8UC1");
}

// Do the convolve once for a frame 
fn create_convolve_value(frame: &Mat,  kernel: &Vec<Vec<f32>>) -> Vec<f32> {
    let mut convolved_values: Vec<f32> = Vec::with_capacity(1500);
    let mut f32_frame = Mat::default();

    frame.convert_to(&mut f32_frame, CV_32F, 1.0, 0.0).expect("Wrong channels");
    for y in 0..f32_frame.rows() {
        for x in 0..frame.cols() {

            let _ = convolved_values.push(convolve_pixel(&f32_frame, x as usize, y as usize, kernel));
/*             println!("CON: {}", convolve_pixel(&f32_frame, x as usize, y as usize, kernel)); */
        }
    }

    convolved_values
}

fn convolve_pixel(frame: &Mat, x: usize, y: usize, kernel: &Vec<Vec<f32>>) -> f32 {
    let mut blurred_pixel_value = 0.0;
    let kernel_size = kernel.len();
    // println!("KERNEL: {:#?}", kernel);
    // println!("Kernel size: {}", kernel_size);
    let center = kernel_size / 2; // Size of whole image and get the center value 
    // println!("Center kernel: {}", center);
    // let mut check = 0;


    // Convert the data type to 32-bit floating point (CV_32FC1) outside the loop

    for ky in 0..kernel_size {
        for kx in 0..kernel_size {
            let pixel_x = (x as i32 - center as i32 + kx as i32) as i32;
            let pixel_y = (y as i32 - center as i32 + ky as i32) as i32;
            // println!("PIXEL Y: {} | PIXEL X: {}", pixel_y, pixel_x);

            // Check if pixel coordinates are within bounds
            if pixel_x >= 0 && pixel_x < frame.cols() && pixel_y >= 0 && pixel_y < frame.rows() {
                let kernel_value = *kernel.get(ky).and_then(|row| row.get(kx)).expect("Invalid kernel access");
                /* println!("Kernel value: {:#?}", *kernel.get(ky).expect("Y not found for kernel"));
                println!("FRAME HERE IN BLUR COVOLUTE: {:#?}", frame); */
                blurred_pixel_value += *frame.at_2d::<f32>(pixel_y, pixel_x).expect("Failed to access pixel") * kernel_value;
                // println!("BLUR PIXEL VALUE: {}", *frame.at_2d::<f32>(pixel_y, pixel_x).expect("Failed to access pixel"));

            }
        }
                        /* check+=1;
                if check == 5 {
                    panic!("AHH");
                } */

    }

    blurred_pixel_value
}
// Function to generate Gaussian kernel
fn generate_gaussian_weight_kernel(size: usize, sigma: f32) -> Vec<Vec<f32>> {
    let mut kernel = vec![vec![0.0; size]; size];
    let center = size / 2;
    
    for y in 0..size {
        for x in 0..size {
            let distance_x = (x as isize - center as isize) as f32;
            let distance_y = (y as isize - center as isize) as f32;
            let exponent = -(distance_x.powi(2) + distance_y.powi(2)) / (2.0 * sigma.powi(2)) as f32;
            kernel[y][x] = (1.0 / (2.0 * consts::PI * sigma.powi(2))).exp() * exponent;
        }
    }

    // println!("Unnormalized KERNEL: {:#?}", kernel);

    kernel
}

fn normalize_kernel(kernel: &Vec<Vec<f32>>) -> Vec<Vec<f32>> {
    // Calculate the sum of all elements in the 2D vector
    let sum: f32 = kernel.iter().map(|row| row.iter().sum::<f32>()).sum();

    // Normalize the kernel by dividing each element by the sum
    let normalized_kernel: Vec<Vec<f32>> = kernel.iter()
        .map(|row| {
            row.iter()
                .map(|&x| x / sum)
                .collect()
        })
        .collect();

    normalized_kernel
}
